{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "9kJRR4aOV2Zm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "collapsed": true,
        "outputId": "444cf8b0-057e-4b9e-bc65-881d8654cd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.5.1\n",
            "  Using cached scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting numpy>=1.19.5 (from scikit-learn==1.5.1)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn==1.5.1)\n",
            "  Using cached scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn==1.5.1)\n",
            "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.1)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Using cached scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.3 MB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.1\n",
            "    Uninstalling numpy-2.3.1:\n",
            "      Successfully uninstalled numpy-2.3.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.1\n",
            "    Uninstalling joblib-1.5.1:\n",
            "      Successfully uninstalled joblib-1.5.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.1\n",
            "    Uninstalling scikit-learn-1.5.1:\n",
            "      Successfully uninstalled scikit-learn-1.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "plotnine 0.14.6 requires scipy<1.16.0,>=1.8.0, but you have scipy 1.16.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed joblib-1.5.1 numpy-2.3.1 scikit-learn-1.5.1 scipy-1.16.0 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "scipy",
                  "sklearn",
                  "threadpoolctl"
                ]
              },
              "id": "6532eb7d44e64a1b92b7f83aecf56949"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install scikit-learn==1.5.1 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(\"✅ Đang dùng sklearn version:\", sklearn.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqFlJLc_cTTd",
        "outputId": "5e94fb7d-e9a9-4ff9-b4dc-f7d5836680b5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đang dùng sklearn version: 1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/transaction_dataset.csv'\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(path, index_col = 0)\n",
        "df.columns = df.columns.str.strip()"
      ],
      "metadata": {
        "id": "NyD-etJbcy_P"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrmW_Ubv6ysB",
        "outputId": "ca4528e7-1fad-4bf4-dcb9-eacc0a2ac742"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# This is for validation process\n",
        "X_train = train_df.drop('FLAG', axis=1)\n",
        "y_train = train_df['FLAG']\n",
        "X_test = test_df.drop('FLAG', axis=1)\n",
        "y_test = test_df['FLAG']"
      ],
      "metadata": {
        "id": "75Ze0LevdKk5"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "\n",
        "class IntelligentImputer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, numeric_fill_value=0, categorical_fill_value='Unknown'):\n",
        "    self.numeric_fill_value = numeric_fill_value\n",
        "    self.categorical_fill_value = categorical_fill_value\n",
        "\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    self.numeric_cols_ = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    self.categorical_cols_ = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "    self.encoder_ = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "\n",
        "    # Create temp data for encoder to learn, fit mustn't be used to fillna\n",
        "    temp_categorical_data = X[self.categorical_cols_].fillna(self.categorical_fill_value)\n",
        "    self.encoder_.fit(temp_categorical_data)\n",
        "\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    X_transformed = X.copy()\n",
        "\n",
        "    if self.numeric_cols_:\n",
        "      X_transformed[self.numeric_cols_] = X_transformed[self.numeric_cols_].fillna(self.numeric_fill_value)\n",
        "\n",
        "    if self.categorical_cols_:\n",
        "      X_transformed[self.categorical_cols_] = X_transformed[self.categorical_cols_].fillna(self.categorical_fill_value)\n",
        "\n",
        "    # Encode using encoder_ fitted before\n",
        "    X_transformed[self.categorical_cols_] = self.encoder_.transform(X_transformed[self.categorical_cols_])\n",
        "    return X_transformed\n",
        "  def get_feature_names_out(self, input_features=None):\n",
        "    return self.numeric_cols_ + self.categorical_cols_"
      ],
      "metadata": {
        "id": "93ORH0x_huko"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ControlCharacterCleaner(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def _remove_control_char(self, s):\n",
        "    cleaned = ''.join(c for c in str(s) if ord(c) >= 32 or c in '\\t\\n\\r')\n",
        "    return cleaned if cleaned.strip() != '' else np.nan\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    self.object_cols_ = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "      X_transformed = X.copy()\n",
        "      for col in self.object_cols_:\n",
        "          X_transformed[col] = X_transformed[col].apply(self._remove_control_char)\n",
        "      return X_transformed\n"
      ],
      "metadata": {
        "id": "P8bDad-7whsh"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Một transformer tùy biến để loại bỏ các cột được chỉ định từ DataFrame.\n",
        "    \"\"\"\n",
        "    def __init__(self, columns_to_drop):\n",
        "        self.columns_to_drop = columns_to_drop\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_transformed = X.copy()\n",
        "        return X_transformed.drop(columns=self.columns_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "mGYwp1bO3S2n"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\n",
        "    'Index',\n",
        "    'Address',\n",
        "    'ERC20 most sent token type',\n",
        "    'ERC20_most_rec_token_type'\n",
        "]"
      ],
      "metadata": {
        "id": "wppxrcvj3cZu"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from ml_transformers import ColumnDropper, ControlCharacterCleaner, IntelligentImputer\n",
        "\n",
        "full_pipeline = Pipeline(steps = [\n",
        "    ('column_dropper', ColumnDropper(columns_to_drop=columns_to_remove)),\n",
        "    ('control_char_cleaner', ControlCharacterCleaner()),\n",
        "    ('intelligent_imputer', IntelligentImputer()),\n",
        "    ('classifier', XGBClassifier())\n",
        "])\n"
      ],
      "metadata": {
        "id": "a5taxy0-xZNk"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_pipeline.fit(X_train, y_train)\n",
        "y_pred = full_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9dNd1SSx4TS",
        "outputId": "2ac4059a-42e7-40cd-996a-05fbb56681db"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1542\n",
            "           1       0.94      0.92      0.93       427\n",
            "\n",
            "    accuracy                           0.97      1969\n",
            "   macro avg       0.96      0.95      0.95      1969\n",
            "weighted avg       0.97      0.97      0.97      1969\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_real = test_df.drop(columns=['FLAG'])\n",
        "y_train_real = test_df['FLAG']\n",
        "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_train_real, y_train_real, test_size=0.2, random_state=42)\n",
        "full_pipeline.fit(X_train_real, y_train_real)\n",
        "y_pred_real = full_pipeline.predict(X_test_real)\n",
        "print(classification_report(y_test_real, y_pred_real))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz1vBQfFyesy",
        "outputId": "407de2f7-f743-4dd9-8bf9-85ec274100ba"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       313\n",
            "           1       0.92      0.89      0.91        81\n",
            "\n",
            "    accuracy                           0.96       394\n",
            "   macro avg       0.95      0.93      0.94       394\n",
            "weighted avg       0.96      0.96      0.96       394\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(full_pipeline, 'full_pipeline.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIZct-9R-25j",
        "outputId": "d303b134-83e0-4217-f4f1-9d9a125712dd"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['full_pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = full_pipeline.named_steps['intelligent_imputer'].encoder_\n",
        "joblib.dump(encoder, 'label_encoder.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JId7v54D6Wk8",
        "outputId": "a2b5135a-120d-435c-9bce-45c21700bf0a"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    }
  ]
}